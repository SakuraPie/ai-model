{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SakuraPie/ai-model/blob/main/sovits_f0%E4%B8%80%E9%94%AE%E8%AE%AD%E7%BB%83.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hw61j0aOOoNZ"
      },
      "source": [
        "**[sovits合集导航](https://github.com/IceKyrin/sovits_guide)**\n",
        "\n",
        "[sovits_f0 git](https://github.com/innnky/so-vits-svc)\n",
        "\n",
        "1、**本colab为Rcell版sovits2.0(f0分支)，仅支持多人模型，模型仅在三个一键脚本内部互通**\n",
        "\n",
        "2、可以使用**预模型（已替换为22050hz）**节省训练时间，id范围0-7，**最多八个人物**，按提示操作即可；**预模型**可以只放一个人物，从头训练至少2个。\n",
        "\n",
        "3、模型自动存储在谷歌盘内，请**定时清理空间**，以免盘满丢失进度。\n",
        "\n",
        "4、**报错**请**先检查数据集和路径**，格式参考数据集制作colab，本colab**经过多人测试通过，已高度自动化**；按提示修改文件名、路径即可，**除非知道自己在做什么**，**不要自己发明新代码、手动创建新路径**\n",
        "\n",
        "5、请确保网络连通性良好，报错也可能是因为网络原因\n",
        "\n",
        "6、只需要保证**最新生成的**D、G.pth,config.json在，即可继续训练；每次**断点继续**训练，都是**步骤完全一样**的从头开始；**请记录自己的初始操作**，每次保持一致\n",
        "\n",
        "7、对于**有一点点基础**的，**断点继续训练**：首次成功运行之后，保存/content/sovits_f0_train/路径下，**configs里的xxx.json**、**filelist里的train/val.txt**、云盘里**最新的G、D.pth**、**dataset里的各人物数据文件夹**，手动上传一下，保证这几个和首次运行一致即可。**不明白就参考第六步，每次都和第一次完全相同的操作即可**\n",
        "\n",
        "前置：[一键制作数据集](https://colab.research.google.com/drive/1avWZ_N5BsQcq45XkwQkDpmp912CLZS0n#scrollTo=xx2oAf90btEy)\n",
        "\n",
        "后置：[一键合成](https://colab.research.google.com/drive/1F3VpHCi9eridGw1F1hbqR7qhXGKuSCus#scrollTo=vjkgBV7j2cVJ)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 查看显卡\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "mZZr0oPu6vit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "SaxypO5jwX__"
      },
      "outputs": [],
      "source": [
        "#@title 准备\n",
        "#@markdown 定义工具函数 `run_command` `run_command_by_line` `get_symbols` 和 `get_tensorboard_showing`\n",
        "# forked from https://www.endpointdev.com/blog/2015/01/getting-realtime-output-using-python/\n",
        "import os\n",
        "import subprocess\n",
        "def run_command(command_args):\n",
        "    def print_pipe(raw):\n",
        "        return print(raw.decode(\"utf-8\"), end='')\n",
        "    try:\n",
        "      process = subprocess.Popen(command_args, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "      out, err = process.communicate()\n",
        "    except:\n",
        "      pass\n",
        "    print_pipe(out)\n",
        "    print_pipe(err)\n",
        "    rc = process.poll()\n",
        "    return rc\n",
        "\n",
        "def run_command_by_line(command_args):\n",
        "    def print_pipe(raw):\n",
        "        return print(raw.decode(\"utf-8\"), end='')\n",
        "    with subprocess.Popen(command_args, stdout=subprocess.PIPE, stderr=subprocess.PIPE) as process:\n",
        "      while process.poll() is None:\n",
        "        print_pipe(process.stdout.readline())\n",
        "      [print_pipe(line) for line in process.stderr.readlines()]\n",
        "    return\n",
        "\n",
        "def get_tensorboard_showing(logdir):\n",
        "    from multiprocessing import Process\n",
        "    from tensorboard import notebook\n",
        "    import tensorflow as tf\n",
        "    import time\n",
        "\n",
        "    def run_tb():\n",
        "        run_command_by_line([\"tensorboard\",\"--reload_interval\", \"30\",  \"--logdir\", logdir, \"--bind_all\"])\n",
        "    \n",
        "    def monitor_tb():\n",
        "        while True:\n",
        "            try:\n",
        "                notebook.display(height=998)\n",
        "                break\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "                time.sleep(3)\n",
        "\n",
        "    if param_enable_tb:\n",
        "        Process(target=run_tb).start()\n",
        "        Process(target=monitor_tb).start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_0vZ-OjHVNu",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 下载依赖库\n",
        "colab_save_space = True #@param {type:\"boolean\"}\n",
        "os.chdir('/content')\n",
        "run_command_by_line([\"git\", \"clone\", \"https://github.com/IceKyrin/sovits_f0_train.git\", \"-b\", \"main\" if colab_save_space else \"main\"])\n",
        "os.chdir('/content/sovits_f0_train')\n",
        "!pip install -r requirements.txt\n",
        "!sudo apt-get install espeak -y\n",
        "!sudo apt-get install p7zip-full p7zip-rar\n",
        "!pip install demjson"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ZOgjdsQgKTfD"
      },
      "outputs": [],
      "source": [
        "#@title 加载Google云端硬盘\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "N3a-FsHghwXS"
      },
      "outputs": [],
      "source": [
        "#@title 解压数据集\n",
        "!mkdir /content/sovits_f0_train/dataset\n",
        "\n",
        "#@markdown 每次解压**一个**，确认完成后**修改名称**、**依次**解压**所有**压缩包\n",
        "\n",
        "#@markdown 数据集制作时，确定的人物名称(前缀加\"out_\",不带zip)\n",
        "DATASETNAME = \"out_qiu\"  #@param {type:\"string\"}\n",
        "#@markdown 压缩包路径(这个名字是接着上一篇的输出zip)\n",
        "ZIP_PATH = \"/content/drive/MyDrive/dataset/out_qiu.zip\"  #@param {type:\"string\"}\n",
        "DATASETPATH = \"/content/sovits_f0_train/\" + DATASETNAME\n",
        "%cd /content/sovits_f0_train/dataset\n",
        "!cp {ZIP_PATH} {DATASETNAME}.zip\n",
        "!unzip -q {DATASETNAME}.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 生成filelist\n",
        "import re\n",
        "import demjson\n",
        "!mkdir /content/sovits_f0_train/filelist\n",
        "%cd /content/sovits_f0_train/\n",
        "\n",
        "\n",
        "def replace_id(f_list, sp_id):\n",
        "    if re.search('wav[|](\\d+)[|]', f_list[0]):\n",
        "        split_char = \"wav|%s|\" % re.search('wav[|](\\d+)[|]', f_list[0]).group(1)\n",
        "    else:\n",
        "        split_char = \"wav|\"\n",
        "    f_list = [x.replace(split_char, f\"wav|{sp_id}|\") for x in f_list]\n",
        "    return f_list\n",
        "\n",
        "\n",
        "# data文件夹下放，各个 工程名/wavs/train(val)(这层可以不要)/xxx.wav\n",
        "# 自动读取每个工程文件夹下的train(val).txt(xxx.wav|无符号文本)\n",
        "#@markdown 默认为0，总体偏移量，不明白别改\n",
        "pre = 0  #@param {type:\"string\"} \n",
        "dataset_path = \"./dataset\"  # 数据合集目录\n",
        "file_train_name = \"train.txt\"\n",
        "file_val_name = \"val.txt\"\n",
        "#@markdown 人物名(**必须与数据集制作时人物名相同，个数也相同，英文逗号隔开**)，**预模型**可以只放一个\n",
        "\n",
        "#@markdown 就是已经在dataset文件夹下解压出的数据文件夹的名称，也是人物名称\n",
        "\n",
        "#@markdown id即为此处人物排序，从0自动开始赋值\n",
        "speakers = \"qiu,x,y,z\" #@param {type:\"string\"}\n",
        "speakers = [speaker.strip() for speaker in speakers.split(\",\")]\n",
        "\n",
        "print(speakers)\n",
        "\n",
        "train_f = open(\"./filelist/train.txt\", \"w\", encoding=\"utf-8\")\n",
        "val_f = open(\"./filelist/val.txt\", \"w\", encoding=\"utf-8\")\n",
        "pre = int(pre)\n",
        "for i in range(pre, len(speakers) + pre):\n",
        "    with open(f\"{dataset_path}/{speakers[i]}/{file_train_name}\", \"r\", encoding=\"utf-8\") as f:\n",
        "        file_list = f.readlines()\n",
        "        train_f.writelines(replace_id(file_list, i))\n",
        "    with open(f\"{dataset_path}/{speakers[i]}/{file_val_name}\", \"r\", encoding=\"utf-8\") as f:\n",
        "        file_list = f.readlines()\n",
        "        val_f.writelines(replace_id(file_list, i))\n",
        "train_f.close()\n",
        "val_f.close()\n"
      ],
      "metadata": {
        "id": "GfkmTW1Z36iq",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qDPyW6pnMpK9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0P9X9SSPl0L",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 生成配置文件 在configs下，记得自己下载保留一份，下次用\n",
        "#@markdown 本colab内可选下载的**预模型已替换为22050hz**，id为0-7可用\n",
        "\n",
        "#@markdown **预模型请直接使用下一步下载的nyarumul.json，id0-7可用，json无需修改**\n",
        "\n",
        "#@markdown **预模型的json可以不改动，只放一个id的数据进去**\n",
        "\n",
        "# forked from https://github.com/CjangCjengh/vits/blob/main/configs/japanese_ss_base2.json\n",
        "\n",
        "#@markdown 44100采样率，训练时长要求高，**和数据集制作时统一采样率**\n",
        "high_sample_rate = False #@param {type:\"boolean\"}\n",
        "#@markdown 配置文件名称\n",
        "json_filename = \"model.json\" #@param {type:\"string\"}\n",
        "#@markdown 训练次数\n",
        "hparams_epochs = 3000 #@param {type:\"integer\"}\n",
        "#@markdown 每隔多少次step保存一次断点\n",
        "hparams_eval_interval = 2000 #@param {type:\"integer\"}\n",
        "#@markdown 单次step的文件数（建议在16以内，若使用44100采样率，在8以内）\n",
        "hparams_batch_size = 16 #@param {type:\"integer\"}\n",
        "#@markdown 训练集文件列表\n",
        "hparams_training_files = \"/content/sovits_f0_train/filelist/train.txt\" #@param {type:\"string\"}\n",
        "#@markdown 验证集文件列表\n",
        "hparams_validation_files = \"/content/sovits_f0_train/filelist/val.txt\"#@param {type:\"string\"}\n",
        "#@markdown 人物名，多个人物用英文逗号隔开，必须**与上面填写的相同**\n",
        "hparams_speaker = \"qiu,x,y,z\" #@param {type:\"string\"}\n",
        "#@markdown 模型名\n",
        "hparams_model_name = \"model\" #@param {type:\"string\"}\n",
        "\n",
        "speakers = [speaker.strip() for speaker in hparams_speaker.split(\",\")]\n",
        "print(\"speakers: \")\n",
        "for i, speaker in enumerate(speakers):\n",
        "  print(\"\\t{a}: {b}\".format(a=i, b=speaker))\n",
        "training_json = {\n",
        "  \"train\": {\n",
        "    \"log_interval\": 200,\n",
        "    \"eval_interval\": hparams_eval_interval,\n",
        "    \"seed\": 1234 ,\n",
        "    \"epochs\": hparams_epochs,\n",
        "    \"learning_rate\": 2e-4,\n",
        "    \"betas\": [0.8, 0.99],\n",
        "    \"eps\": 1e-9,\n",
        "    \"batch_size\": hparams_batch_size,\n",
        "    \"fp16_run\": True,\n",
        "    \"lr_decay\": 0.999875,\n",
        "    \"segment_size\": 16384 if high_sample_rate else 8192,\n",
        "    \"init_lr_ratio\": 1,\n",
        "    \"warmup_epochs\": 0,\n",
        "    \"c_mel\": 45,\n",
        "    \"c_kl\": 1.0\n",
        "  },\n",
        "  \"data\": {\n",
        "    \"training_files\": hparams_training_files,\n",
        "    \"validation_files\": hparams_validation_files,\n",
        "    \"text_cleaners\":[\"english_cleaners2\"],\n",
        "    \"max_wav_value\": 32768.0,\n",
        "    \"sampling_rate\": 44100 if high_sample_rate else 22050,\n",
        "    \"filter_length\": 2048 if high_sample_rate else 1024,\n",
        "    \"hop_length\": 512 if high_sample_rate else 256,\n",
        "    \"win_length\": 2048 if high_sample_rate else 1024,\n",
        "    \"n_mel_channels\": 128 if high_sample_rate else 80,\n",
        "    \"mel_fmin\": 0.0,\n",
        "    \"mel_fmax\": None,\n",
        "    \"add_blank\": True,\n",
        "    \"n_speakers\": len(speakers) if len(speakers) > 1 else 2\n",
        "  },\n",
        "  \"model\": {\n",
        "    \"inter_channels\": 192,\n",
        "    \"hidden_channels\": 256,\n",
        "    \"filter_channels\": 768,\n",
        "    \"n_heads\": 2,\n",
        "    \"n_layers\": 6,\n",
        "    \"kernel_size\": 3,\n",
        "    \"p_dropout\": 0.1,\n",
        "    \"resblock\": \"1\",\n",
        "    \"resblock_kernel_sizes\": [3,7,11],\n",
        "    \"resblock_dilation_sizes\": [[1,3,5], [1,3,5], [1,3,5]],\n",
        "    \"upsample_rates\": [8,8,4,2] if high_sample_rate else [8,8,2,2],\n",
        "    \"upsample_initial_channel\": 512,\n",
        "    \"upsample_kernel_sizes\": [16,16,4,4],\n",
        "    \"n_layers_q\": 3,\n",
        "    \"use_spectral_norm\": False\n",
        "  },\n",
        "  \"speakers\": speakers\n",
        "}\n",
        "\n",
        "if len(speakers) > 1:\n",
        "  training_json[\"model\"][\"gin_channels\"] = 256\n",
        "\n",
        "import demjson\n",
        "os.chdir('/content/sovits_f0_train/configs')\n",
        "training_json_text = demjson.encode(training_json)\n",
        "with open(json_filename, \"w\") as file:\n",
        "  file.write(training_json_text)\n",
        "\n",
        "os.chdir('/content/sovits_f0_train')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqSbYJ5ack09"
      },
      "outputs": [],
      "source": [
        "#@title 预处理\n",
        "os.chdir('/content/sovits_f0_train/monotonic_align')\n",
        "!python setup.py build_ext --inplace\n",
        "os.chdir('/content/sovits_f0_train')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "若**使用预模型**（2.0只能用2.0的预模型，**下面打钩自动下载**），直接在预模型基础上训练，节省时间\n",
        "\n",
        "使用预模型读取pth文件后，文件名的G_steps.pth，steps会乱是正常现象（使用v100训练，batch_size为32，colab显存不够改成了16，所以会乱掉，保存最新生成的模型即可）\n",
        "\n",
        "程序读取一次预模型后，以后断点恢复训练、用**最新生成的一组pth继续训练**"
      ],
      "metadata": {
        "id": "mXsu-rXYx2Xs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown 22050hz预模型,id为0-7可用\n",
        "!mkdir /content/drive/MyDrive/nyarumul/\n",
        "pre_pth = True #@param {type:\"boolean\"}\n",
        "if pre_pth:\n",
        "  !wget https://huggingface.co/spaces/xiaolang/sovits_f0/resolve/main/G_50000.pth -O /content/drive/MyDrive/nyarumul/G_50000.pth\n",
        "  !wget https://huggingface.co/spaces/xiaolang/sovits_f0/resolve/main/D_50000.pth -O /content/drive/MyDrive/nyarumul/D_50000.pth"
      ],
      "metadata": {
        "id": "nz3KJCcBVTlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltU2JXpxIh-K"
      },
      "outputs": [],
      "source": [
        "#@title 训练\n",
        "\n",
        "#@markdown 启用tensorboard可视化数据，首次运行可能十分钟左右出现数据\n",
        "\n",
        "#@markdown epoch次数看/content/drive/MyDrive/模型名/train.log\n",
        "\n",
        "#@markdown **首次**使用**预模型**时，成功运行约十五分钟后，发现自动保存了**新的.pth**（可能是G/D_20000.pth），然后**删除G/D_50000.pth**\n",
        "\n",
        "#@markdown 模型名（使用预模型则为nyarumul）\n",
        "hparams_model_name = \"nyarumul\"  # @param {type:\"string\"}\n",
        "#@markdown 模型自动保存到 /云盘路径/模型名 ,记得定期清理空间！\n",
        "param_enable_tb = True  # @param {type:\"boolean\"}\n",
        "if param_enable_tb:\n",
        "  #@markdown 云盘路径（一般不改） （定时清云盘！！！pth里保留最新的俩）\n",
        "  logdir = \"/content/drive/MyDrive/\"  # @param {type:\"string\"}\n",
        "  new_pth_dir = os.path.join(logdir, hparams_model_name)\n",
        "  get_tensorboard_showing(new_pth_dir)\n",
        "os.chdir('/content/sovits_f0_train')\n",
        "#@markdown 配置文件json名（使用预模型则为nyarumul.json）\n",
        "json_filename = \"nyarumul.json\"  # @param {type:\"string\"}\n",
        "# 这里魔改过until.py的args\n",
        "run_command_by_line([\"python\", \"train_ms.py\", \"-c\", \"configs/{json}\".format(json=json_filename), \"-m\", hparams_model_name, \"-l\",logdir])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 精简模型\n",
        "import torch\n",
        "#@markdown 模型名，数字是最新的模型steps\n",
        "new_model_name = \"G_207000.pth\"  # @param {type:\"string\"}\n",
        "checkpoint_dict = torch.load(f\"{new_pth_dir}/{new_model_name}\")\n",
        "iteration = checkpoint_dict['iteration']\n",
        "learning_rate = checkpoint_dict['learning_rate']\n",
        "optimizer = checkpoint_dict['optimizer']\n",
        "saved_state_dict = checkpoint_dict['model']\n",
        "print(iteration)\n",
        "#@markdown 输出xxx_epoch.pth；此模型**仅供合成使用**，去除训练信息、体积约为1/3，**无法训练使用**\n",
        "torch.save({'model': saved_state_dict,\n",
        "  'iteration': None,\n",
        "  'optimizer': None,\n",
        "  'learning_rate': None}, f'{new_pth_dir}/{iteration}_epochs.pth')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "lwa9GQx1X0L_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}